{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q -U \"torch==2.1.2\" tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:21:08.910939Z",
     "iopub.status.busy": "2024-02-19T15:21:08.910074Z",
     "iopub.status.idle": "2024-02-19T15:21:38.985512Z",
     "shell.execute_reply": "2024-02-19T15:21:38.984371Z",
     "shell.execute_reply.started": "2024-02-19T15:21:08.910897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q -U \"transformers==4.36.2\" \"datasets==2.16.1\" \"accelerate==0.26.1\" \"bitsandbytes==0.42.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:21:38.987437Z",
     "iopub.status.busy": "2024-02-19T15:21:38.987022Z",
     "iopub.status.idle": "2024-02-19T15:22:32.891236Z",
     "shell.execute_reply": "2024-02-19T15:22:32.890008Z",
     "shell.execute_reply.started": "2024-02-19T15:21:38.987398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q -U git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e\n",
    "!pip install -q -U git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:22:32.894943Z",
     "iopub.status.busy": "2024-02-19T15:22:32.894556Z",
     "iopub.status.idle": "2024-02-19T15:22:32.900259Z",
     "shell.execute_reply": "2024-02-19T15:22:32.899115Z",
     "shell.execute_reply.started": "2024-02-19T15:22:32.894904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:22:32.90177Z",
     "iopub.status.busy": "2024-02-19T15:22:32.901507Z",
     "iopub.status.idle": "2024-02-19T15:22:32.914498Z",
     "shell.execute_reply": "2024-02-19T15:22:32.913622Z",
     "shell.execute_reply.started": "2024-02-19T15:22:32.901747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:22:32.915866Z",
     "iopub.status.busy": "2024-02-19T15:22:32.915638Z",
     "iopub.status.idle": "2024-02-19T15:22:48.260443Z",
     "shell.execute_reply": "2024-02-19T15:22:48.259636Z",
     "shell.execute_reply.started": "2024-02-19T15:22:32.915846Z"
    },
    "papermill": {
     "duration": 14.485002,
     "end_time": "2023-10-16T11:00:18.917449",
     "exception": false,
     "start_time": "2023-10-16T11:00:04.432447",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:22:48.262366Z",
     "iopub.status.busy": "2024-02-19T15:22:48.261986Z",
     "iopub.status.idle": "2024-02-19T15:22:48.267436Z",
     "shell.execute_reply": "2024-02-19T15:22:48.266395Z",
     "shell.execute_reply.started": "2024-02-19T15:22:48.26233Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "print(f\"pytorch version {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:22:48.26905Z",
     "iopub.status.busy": "2024-02-19T15:22:48.268538Z",
     "iopub.status.idle": "2024-02-19T15:22:48.284682Z",
     "shell.execute_reply": "2024-02-19T15:22:48.283708Z",
     "shell.execute_reply.started": "2024-02-19T15:22:48.268983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on balanced\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device=\"balanced\"\n",
    "print(f\"working on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:22:48.286089Z",
     "iopub.status.busy": "2024-02-19T15:22:48.28578Z",
     "iopub.status.idle": "2024-02-19T15:22:48.802257Z",
     "shell.execute_reply": "2024-02-19T15:22:48.80152Z",
     "shell.execute_reply.started": "2024-02-19T15:22:48.286056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filename = \"./all-data.csv\"\n",
    "\n",
    "df = pd.read_csv(filename, \n",
    "                 names=[\"sentiment\", \"text\"],\n",
    "                 encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "\n",
    "X_train = list()\n",
    "X_test = list()\n",
    "for sentiment in [\"positive\", \"neutral\", \"negative\"]:\n",
    "    train, test  = train_test_split(df[df.sentiment==sentiment], \n",
    "                                    train_size=300,\n",
    "                                    test_size=300, \n",
    "                                    random_state=42)\n",
    "    X_train.append(train)\n",
    "    X_test.append(test)\n",
    "\n",
    "X_train = pd.concat(X_train).sample(frac=1, random_state=10)\n",
    "X_test = pd.concat(X_test)\n",
    "\n",
    "eval_idx = [idx for idx in df.index if idx not in list(X_train.index) + list(X_test.index)]\n",
    "X_eval = df[df.index.isin(eval_idx)]\n",
    "X_eval = (X_eval\n",
    "          .groupby('sentiment', group_keys=False)\n",
    "          .apply(lambda x: x.sample(n=50, random_state=10, replace=True)))\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{data_point[\"text\"]}] = {data_point[\"sentiment\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{data_point[\"text\"]}] = \"\"\".strip()\n",
    "\n",
    "X_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1), \n",
    "                       columns=[\"text\"])\n",
    "X_eval = pd.DataFrame(X_eval.apply(generate_prompt, axis=1), \n",
    "                      columns=[\"text\"])\n",
    "\n",
    "y_true = X_test.sentiment\n",
    "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:22:48.805713Z",
     "iopub.status.busy": "2024-02-19T15:22:48.805429Z",
     "iopub.status.idle": "2024-02-19T15:22:48.814457Z",
     "shell.execute_reply": "2024-02-19T15:22:48.813475Z",
     "shell.execute_reply.started": "2024-02-19T15:22:48.80569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = ['positive', 'neutral', 'negative']\n",
    "    mapping = {'positive': 2, 'neutral': 1, 'none':1, 'negative': 0}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:22:48.815759Z",
     "iopub.status.busy": "2024-02-19T15:22:48.815516Z",
     "iopub.status.idle": "2024-02-19T15:25:52.446459Z",
     "shell.execute_reply": "2024-02-19T15:25:52.445664Z",
     "shell.execute_reply.started": "2024-02-19T15:22:48.815738Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.80s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/user10/code/datamining/input\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                          trust_remote_code=True,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:25:52.447931Z",
     "iopub.status.busy": "2024-02-19T15:25:52.447624Z",
     "iopub.status.idle": "2024-02-19T15:25:52.455064Z",
     "shell.execute_reply": "2024-02-19T15:25:52.454108Z",
     "shell.execute_reply.started": "2024-02-19T15:25:52.447907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        prompt = X_test.iloc[i][\"text\"]\n",
    "        pipe = pipeline(task=\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer, \n",
    "                        max_new_tokens = 1, \n",
    "                        temperature = 0.0,\n",
    "                       )\n",
    "        result = pipe(prompt)\n",
    "        answer = result[0]['generated_text'].split(\"=\")[-1]\n",
    "        if \"positive\" in answer:\n",
    "            y_pred.append(\"positive\")\n",
    "        elif \"negative\" in answer:\n",
    "            y_pred.append(\"negative\")\n",
    "        elif \"neutral\" in answer:\n",
    "            y_pred.append(\"neutral\")\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:25:52.456432Z",
     "iopub.status.busy": "2024-02-19T15:25:52.45609Z",
     "iopub.status.idle": "2024-02-19T15:31:20.605915Z",
     "shell.execute_reply": "2024-02-19T15:31:20.604946Z",
     "shell.execute_reply.started": "2024-02-19T15:25:52.456403Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [01:49<00:00,  8.19it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(test, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:31:20.608098Z",
     "iopub.status.busy": "2024-02-19T15:31:20.607384Z",
     "iopub.status.idle": "2024-02-19T15:31:20.631677Z",
     "shell.execute_reply": "2024-02-19T15:31:20.630744Z",
     "shell.execute_reply.started": "2024-02-19T15:31:20.608062Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.374\n",
      "Accuracy for label 0: 0.027\n",
      "Accuracy for label 1: 0.937\n",
      "Accuracy for label 2: 0.160\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.03      0.05       300\n",
      "           1       0.34      0.94      0.50       300\n",
      "           2       0.68      0.16      0.26       300\n",
      "\n",
      "    accuracy                           0.37       900\n",
      "   macro avg       0.64      0.37      0.27       900\n",
      "weighted avg       0.64      0.37      0.27       900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  8 287   5]\n",
      " [  1 281  18]\n",
      " [  0 252  48]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 900\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test),len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:31:20.63299Z",
     "iopub.status.busy": "2024-02-19T15:31:20.632722Z",
     "iopub.status.idle": "2024-02-19T15:31:23.479593Z",
     "shell.execute_reply": "2024-02-19T15:31:23.478212Z",
     "shell.execute_reply.started": "2024-02-19T15:31:20.632967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_dir=\"trained_weigths\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=16, \n",
    "        lora_dropout=0.1,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        target_modules=\"all-linear\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    # directory to save and repository id\n",
    "    num_train_epochs=3,                       # number of training epochs\n",
    "    per_device_train_batch_size=1,            # batch size per device during training\n",
    "    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,                         # log every 10 steps\n",
    "    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    report_to=\"tensorboard\",                  # report metrics to tensorboard\n",
    "    evaluation_strategy=\"epoch\"               # save checkpoint every epoch\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=1024,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:31:23.481197Z",
     "iopub.status.busy": "2024-02-19T15:31:23.480899Z",
     "iopub.status.idle": "2024-02-19T15:33:05.89364Z",
     "shell.execute_reply": "2024-02-19T15:33:05.892738Z",
     "shell.execute_reply.started": "2024-02-19T15:31:23.481164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:33:05.895578Z",
     "iopub.status.busy": "2024-02-19T15:33:05.894879Z",
     "iopub.status.idle": "2024-02-19T15:33:09.878108Z",
     "shell.execute_reply": "2024-02-19T15:33:09.877301Z",
     "shell.execute_reply.started": "2024-02-19T15:33:05.895541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save trained model and tokenizer\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:33:09.879809Z",
     "iopub.status.busy": "2024-02-19T15:33:09.879196Z",
     "iopub.status.idle": "2024-02-19T15:33:16.414572Z",
     "shell.execute_reply": "2024-02-19T15:33:16.413594Z",
     "shell.execute_reply.started": "2024-02-19T15:33:09.879781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:33:16.415998Z",
     "iopub.status.busy": "2024-02-19T15:33:16.415701Z",
     "iopub.status.idle": "2024-02-19T15:33:16.423616Z",
     "shell.execute_reply": "2024-02-19T15:33:16.422854Z",
     "shell.execute_reply.started": "2024-02-19T15:33:16.415972Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'peft_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m [model, tokenizer, peft_config, trainer, train_data, eval_data, bnb_config, training_arguments]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m [df, X_train, X_eval]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m [TrainingArguments, SFTTrainer, LoraConfig, BitsAndBytesConfig]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'peft_config' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del [model, tokenizer, peft_config, trainer, train_data, eval_data, bnb_config, training_arguments]\n",
    "del [df, X_train, X_eval]\n",
    "del [TrainingArguments, SFTTrainer, LoraConfig, BitsAndBytesConfig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:33:16.424959Z",
     "iopub.status.busy": "2024-02-19T15:33:16.424703Z",
     "iopub.status.idle": "2024-02-19T15:33:46.018557Z",
     "shell.execute_reply": "2024-02-19T15:33:46.017451Z",
     "shell.execute_reply.started": "2024-02-19T15:33:16.424936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "for _ in range(100):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:33:46.023673Z",
     "iopub.status.busy": "2024-02-19T15:33:46.023367Z",
     "iopub.status.idle": "2024-02-19T15:33:47.047959Z",
     "shell.execute_reply": "2024-02-19T15:33:47.046745Z",
     "shell.execute_reply.started": "2024-02-19T15:33:46.023647Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 18 23:19:30 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.113.01             Driver Version: 535.113.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 27%   33C    P8              25W / 250W |   6387MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8               8W / 250W |      0MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:D9:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8               4W / 250W |      0MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     30647      C   ...niconda3/envs/datamining/bin/python      540MiB |\n",
      "|    0   N/A  N/A     39744      C   ...niconda3/envs/datamining/bin/python     4564MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:33:47.049911Z",
     "iopub.status.busy": "2024-02-19T15:33:47.049597Z",
     "iopub.status.idle": "2024-02-19T15:34:49.641179Z",
     "shell.execute_reply": "2024-02-19T15:34:49.640347Z",
     "shell.execute_reply.started": "2024-02-19T15:33:47.049882Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.17s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./merged_model/tokenizer_config.json',\n",
       " './merged_model/special_tokens_map.json',\n",
       " './merged_model/tokenizer.model',\n",
       " './merged_model/added_tokens.json',\n",
       " './merged_model/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "finetuned_model = \"./trained_weigths/\"\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/user10/code/datamining/input\")\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "     finetuned_model,\n",
    "     torch_dtype=compute_dtype,\n",
    "     return_dict=False,\n",
    "     low_cpu_mem_usage=True,\n",
    "     device_map=\"balanced\",\n",
    ")\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"./merged_model\",safe_serialization=True, max_shard_size=\"2GB\")\n",
    "tokenizer.save_pretrained(\"./merged_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-02-19T15:34:49.644055Z",
     "iopub.status.busy": "2024-02-19T15:34:49.643414Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:58<00:00, 15.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.834\n",
      "Accuracy for label 0: 0.893\n",
      "Accuracy for label 1: 0.830\n",
      "Accuracy for label 2: 0.780\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       300\n",
      "           1       0.73      0.83      0.78       300\n",
      "           2       0.85      0.78      0.81       300\n",
      "\n",
      "    accuracy                           0.83       900\n",
      "   macro avg       0.84      0.83      0.84       900\n",
      "weighted avg       0.84      0.83      0.84       900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[268  29   3]\n",
      " [ 12 249  39]\n",
      " [  2  64 234]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(test, merged_model, tokenizer)\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'text': X_test[\"text\"], \n",
    "                           'y_true':y_true, \n",
    "                           'y_pred': y_pred},\n",
    "                         )\n",
    "evaluation.to_csv(\"test_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 622510,
     "sourceId": 1192499,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 735,
     "modelInstanceId": 3090,
     "sourceId": 4295,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
